<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Demonstration 1: Classification Problems | SOST70033 Data Science Modelling</title>
  <meta name="description" content="Notebook hosting practical materials for SOST70033." />
  <meta name="generator" content="bookdown 0.38 and GitBook 2.6.7" />

  <meta property="og:title" content="Demonstration 1: Classification Problems | SOST70033 Data Science Modelling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Notebook hosting practical materials for SOST70033." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Demonstration 1: Classification Problems | SOST70033 Data Science Modelling" />
  
  <meta name="twitter:description" content="Notebook hosting practical materials for SOST70033." />
  

<meta name="author" content="Dr.¬†Ioana Macoveciuc" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="overview-2.html"/>
<link rel="next" href="demonstration-2-poisson-versus-linear-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/logos/uom_logo.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="part"><span><b>Section 1</b></span></li>
<li class="chapter" data-level="" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="demonstration-a-more-in-depth-consideration-of-model-accuracy.html"><a href="demonstration-a-more-in-depth-consideration-of-model-accuracy.html"><i class="fa fa-check"></i>Demonstration: A more in-depth consideration of model accuracy</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-a-more-in-depth-consideration-of-model-accuracy.html"><a href="demonstration-a-more-in-depth-consideration-of-model-accuracy.html#the-simulation"><i class="fa fa-check"></i>The Simulation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html"><i class="fa fa-check"></i>Practical 1</a>
<ul>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-1"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-2"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-3"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-4"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-5"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-6"><i class="fa fa-check"></i>Task 6</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-7"><i class="fa fa-check"></i>Task 7</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-8"><i class="fa fa-check"></i>Task 8</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-9"><i class="fa fa-check"></i>Task 9</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-10"><i class="fa fa-check"></i>Task 10</a></li>
<li class="chapter" data-level="" data-path="practical-1.html"><a href="practical-1.html#task-11"><i class="fa fa-check"></i>Task 11</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-2.html"><a href="practical-2.html"><i class="fa fa-check"></i>Practical 2</a>
<ul>
<li class="chapter" data-level="" data-path="practical-2.html"><a href="practical-2.html#task-1-1"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-2.html"><a href="practical-2.html#task-2-1"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical-2.html"><a href="practical-2.html#task-3-1"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="practical-2.html"><a href="practical-2.html#task-4-1"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="practical-2.html"><a href="practical-2.html#task-5-1"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="practical-2.html"><a href="practical-2.html#task-6-1"><i class="fa fa-check"></i>Task 6</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html"><i class="fa fa-check"></i>Answers</a>
<ul>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#practical-1-1"><i class="fa fa-check"></i>Practical 1</a>
<ul>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-1-2"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-2-2"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-3-2"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-4-2"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-5-2"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-6-2"><i class="fa fa-check"></i>Task 6</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-7-1"><i class="fa fa-check"></i>Task 7</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-8-1"><i class="fa fa-check"></i>Task 8</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-9-1"><i class="fa fa-check"></i>Task 9</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-10-1"><i class="fa fa-check"></i>Task 10</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-11-1"><i class="fa fa-check"></i>Task 11</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#practical-2-1"><i class="fa fa-check"></i>Practical 2</a>
<ul>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-1-3"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-2-3"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-3-3"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-4-3"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-5-3"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="answers.html"><a href="answers.html#task-6-3"><i class="fa fa-check"></i>Task 6</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Section 2</b></span></li>
<li class="chapter" data-level="" data-path="overview-1.html"><a href="overview-1.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="demonstration-1.html"><a href="demonstration-1.html"><i class="fa fa-check"></i>Demonstration 1</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1.html"><a href="demonstration-1.html#simple-linear-models-without-intercept"><i class="fa fa-check"></i>Simple Linear Models Without Intercept</a></li>
<li class="chapter" data-level="" data-path="demonstration-1.html"><a href="demonstration-1.html#simple-linear-models-with-intercept"><i class="fa fa-check"></i>Simple Linear Models with Intercept</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2.html"><a href="demonstration-2.html"><i class="fa fa-check"></i>Demonstration 2</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2.html"><a href="demonstration-2.html#population-parameters-and-estimated-coefficients"><i class="fa fa-check"></i>Population Parameters and Estimated Coefficients</a></li>
<li class="chapter" data-level="" data-path="demonstration-2.html"><a href="demonstration-2.html#what-happens-if-we-reduce-noise"><i class="fa fa-check"></i>What happens if we <em>reduce</em> noise?</a></li>
<li class="chapter" data-level="" data-path="demonstration-2.html"><a href="demonstration-2.html#what-happens-if-we-increase-noise"><i class="fa fa-check"></i>What happens if we <em>increase</em> noise?</a></li>
<li class="chapter" data-level="" data-path="demonstration-2.html"><a href="demonstration-2.html#how-does-noise-affect-confidence-intervals-for-the-coefficients"><i class="fa fa-check"></i>How does noise affect confidence intervals for the coefficients?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html"><i class="fa fa-check"></i>Practical 1</a>
<ul>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-1-4"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-2-4"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-3-4"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-4-4"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-5-4"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-6-4"><i class="fa fa-check"></i>Task 6</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-7-2"><i class="fa fa-check"></i>Task 7</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-8-2"><i class="fa fa-check"></i>Task 8</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-9-2"><i class="fa fa-check"></i>Task 9</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-10-2"><i class="fa fa-check"></i>Task 10</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-11-2"><i class="fa fa-check"></i>Task 11</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-12"><i class="fa fa-check"></i>Task 12</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-13"><i class="fa fa-check"></i>Task 13</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-14"><i class="fa fa-check"></i>Task 14</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-15"><i class="fa fa-check"></i>Task 15</a></li>
<li class="chapter" data-level="" data-path="practical-1-2.html"><a href="practical-1-2.html#task-16"><i class="fa fa-check"></i>Task 16</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-2-2.html"><a href="practical-2-2.html"><i class="fa fa-check"></i>Practical 2</a>
<ul>
<li class="chapter" data-level="" data-path="practical-2-2.html"><a href="practical-2-2.html#task-1-5"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-2-2.html"><a href="practical-2-2.html#task-2-5"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical-2-2.html"><a href="practical-2-2.html#task-3-5"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="practical-2-2.html"><a href="practical-2-2.html#task-4-5"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="practical-2-2.html"><a href="practical-2-2.html#task-5-5"><i class="fa fa-check"></i>Task 5</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-3-the-quality-of-red-bordeaux-vintages.html"><a href="practical-3-the-quality-of-red-bordeaux-vintages.html"><i class="fa fa-check"></i>Practical 3: The Quality of Red Bordeaux Vintages</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html"><i class="fa fa-check"></i>Answers</a>
<ul>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#practical-1-3"><i class="fa fa-check"></i>Practical 1</a>
<ul>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-1-6"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-2-6"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-3-6"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-4-6"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-5-6"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-6-5"><i class="fa fa-check"></i>Task 6</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-7-3"><i class="fa fa-check"></i>Task 7</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-8-3"><i class="fa fa-check"></i>Task 8</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-9-3"><i class="fa fa-check"></i>Task 9</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-10-3"><i class="fa fa-check"></i>Task 10</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-11-3"><i class="fa fa-check"></i>Task 11</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-12-1"><i class="fa fa-check"></i>Task 12</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-13-1"><i class="fa fa-check"></i>Task 13</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-14-1"><i class="fa fa-check"></i>Task 14</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-15-1"><i class="fa fa-check"></i>Task 15</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-16-1"><i class="fa fa-check"></i>Task 16</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#practical-2-3"><i class="fa fa-check"></i>Practical 2</a>
<ul>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-1-7"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-2-7"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-3-7"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-4-7"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#task-5-7"><i class="fa fa-check"></i>Task 5</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-1.html"><a href="answers-1.html#practical-3-the-quality-of-red-bordeaux-vintages-1"><i class="fa fa-check"></i>Practical 3: The Quality of Red Bordeaux Vintages</a></li>
</ul></li>
<li class="part"><span><b>Section 3</b></span></li>
<li class="chapter" data-level="" data-path="overview-2.html"><a href="overview-2.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html"><i class="fa fa-check"></i>Demonstration 1: Classification Problems</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#dataset-and-variables"><i class="fa fa-check"></i>Dataset and Variables</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#correlation-matrix-and-plot"><i class="fa fa-check"></i>Correlation Matrix and Plot</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#classic-logistic-regression"><i class="fa fa-check"></i>‚ÄúClassic‚Äù Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#confusion-matrix"><i class="fa fa-check"></i>Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#logistic-regression-in-statistical-learning"><i class="fa fa-check"></i>Logistic Regression in Statistical Learning</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#linear-discriminant-analysis"><i class="fa fa-check"></i>Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i>Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#k-nearest-neighbours"><i class="fa fa-check"></i><span class="math inline">\(K\)</span>-nearest neighbours</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-classification-problems.html"><a href="demonstration-1-classification-problems.html#naive-bayes"><i class="fa fa-check"></i>Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2-poisson-versus-linear-regression.html"><a href="demonstration-2-poisson-versus-linear-regression.html"><i class="fa fa-check"></i>Demonstration 2: Poisson versus Linear Regression</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-poisson-versus-linear-regression.html"><a href="demonstration-2-poisson-versus-linear-regression.html#the-linear-model"><i class="fa fa-check"></i>The Linear Model</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-poisson-versus-linear-regression.html"><a href="demonstration-2-poisson-versus-linear-regression.html#approaches-to-variable-coding"><i class="fa fa-check"></i>Approaches to variable coding</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-poisson-versus-linear-regression.html"><a href="demonstration-2-poisson-versus-linear-regression.html#plotting-coefficient-estimates"><i class="fa fa-check"></i>Plotting Coefficient Estimates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2-poisson-versus-linear-regression.html"><a href="demonstration-2-poisson-versus-linear-regression.html#the-poisson-model"><i class="fa fa-check"></i>The Poisson Model</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-poisson-versus-linear-regression.html"><a href="demonstration-2-poisson-versus-linear-regression.html#linear-versus-poisson-regression"><i class="fa fa-check"></i>Linear versus Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html"><i class="fa fa-check"></i>Practical: Predicting a company‚Äôs bankruptcy</a>
<ul>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#data-and-variables"><i class="fa fa-check"></i>Data and Variables</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#importing-the-data"><i class="fa fa-check"></i>Importing the data</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#loading-required-packages"><i class="fa fa-check"></i>Loading required packages</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#correlation-matrix-and-plot-1"><i class="fa fa-check"></i>Correlation Matrix and Plot</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#logistic-regression"><i class="fa fa-check"></i>Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#explaining-the-logit"><i class="fa fa-check"></i>Explaining the Logit</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#tasks-linear-discriminant-analysis"><i class="fa fa-check"></i>Tasks: Linear Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-1-8"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-2-8"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-3-8"><i class="fa fa-check"></i>Task 3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#tasks-quadratic-discriminant-analysis"><i class="fa fa-check"></i>Tasks: Quadratic Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-1-9"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-2-9"><i class="fa fa-check"></i>Task 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#tasks-k-nearest-neighbours"><i class="fa fa-check"></i>Tasks: <span class="math inline">\(K\)</span>-nearest neighbours</a>
<ul>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-1-10"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-2-10"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-3-9"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-4-8"><i class="fa fa-check"></i>Task 4</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#tasks-naive-bayes"><i class="fa fa-check"></i>Tasks: Naive Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-1-11"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical-predicting-a-companys-bankruptcy.html"><a href="practical-predicting-a-companys-bankruptcy.html#task-2-11"><i class="fa fa-check"></i>Task 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html"><i class="fa fa-check"></i>Answers</a>
<ul>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#practical-predicting-a-companys-bankruptcy-1"><i class="fa fa-check"></i>Practical: Predicting a company‚Äôs bankruptcy</a>
<ul>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#data-and-variables-1"><i class="fa fa-check"></i>Data and Variables</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#importing-the-data-1"><i class="fa fa-check"></i>Importing the data</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#loading-required-packages-1"><i class="fa fa-check"></i>Loading required packages</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#correlation-matrix-and-plot-2"><i class="fa fa-check"></i>Correlation Matrix and Plot</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#logistic-regression-1"><i class="fa fa-check"></i>Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#linear-discriminant-analysis-1"><i class="fa fa-check"></i>Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#quadratic-discriminant-analysis-1"><i class="fa fa-check"></i>Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#k-nearest-neighbours-1"><i class="fa fa-check"></i><span class="math inline">\(K\)</span>-nearest neighbours</a></li>
<li class="chapter" data-level="" data-path="answers-2.html"><a href="answers-2.html#naive-bayes-1"><i class="fa fa-check"></i>Naive Bayes</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Section 4</b></span></li>
<li class="chapter" data-level="" data-path="overview-3.html"><a href="overview-3.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-cross-validation.html"><a href="demonstration-1-cross-validation.html"><i class="fa fa-check"></i>Demonstration 1: Cross-validation</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-cross-validation.html"><a href="demonstration-1-cross-validation.html#data-and-variables-2"><i class="fa fa-check"></i>Data and Variables</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-cross-validation.html"><a href="demonstration-1-cross-validation.html#the-validation-set-approach"><i class="fa fa-check"></i>The Validation Set Approach</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-cross-validation.html"><a href="demonstration-1-cross-validation.html#leave-one-out-cross-validation"><i class="fa fa-check"></i>Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-cross-validation.html"><a href="demonstration-1-cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><span class="math inline">\(k\)</span>-Fold Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2-bootstrapping.html"><a href="demonstration-2-bootstrapping.html"><i class="fa fa-check"></i>Demonstration 2: Bootstrapping</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-bootstrapping.html"><a href="demonstration-2-bootstrapping.html#data-and-variables-3"><i class="fa fa-check"></i>Data and Variables</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-bootstrapping.html"><a href="demonstration-2-bootstrapping.html#estimating-the-accuracy-of-a-statistic-of-interest"><i class="fa fa-check"></i>Estimating the Accuracy of a Statistic of Interest</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-bootstrapping.html"><a href="demonstration-2-bootstrapping.html#estimating-the-accuracy-of-a-linear-regression-model"><i class="fa fa-check"></i>Estimating the Accuracy of a Linear Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html"><i class="fa fa-check"></i>Practical</a>
<ul>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#part-i-the-validation-set-approach"><i class="fa fa-check"></i>Part I: The Validation Set Approach</a>
<ul>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-1-16"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-2-16"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-3-12"><i class="fa fa-check"></i>Task 3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#part-ii-leave-one-out-cross-validation"><i class="fa fa-check"></i>Part II: Leave-one-out Cross-validation</a>
<ul>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-1-17"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-2-17"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-3-13"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-4-10"><i class="fa fa-check"></i>Task 4</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#part-iii-the-bootstrap"><i class="fa fa-check"></i>Part III: The Bootstrap</a>
<ul>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-1-18"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-2-18"><i class="fa fa-check"></i>Task 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#bonus"><i class="fa fa-check"></i>Bonus</a>
<ul>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-1-19"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-2-19"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-3-14"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-4-11"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-5-8"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-6-6"><i class="fa fa-check"></i>Task 6</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-7-4"><i class="fa fa-check"></i>Task 7</a></li>
<li class="chapter" data-level="" data-path="practical.html"><a href="practical.html#task-8-4"><i class="fa fa-check"></i>Task 8</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html"><i class="fa fa-check"></i>Answers</a>
<ul>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#part-i-the-validation-set-approach-1"><i class="fa fa-check"></i>Part I: The Validation Set Approach</a>
<ul>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-1-20"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-2-20"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-3-15"><i class="fa fa-check"></i>Task 3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#part-ii-leave-one-out-cross-validation-1"><i class="fa fa-check"></i>Part II: Leave-one-out Cross-validation</a>
<ul>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-1-21"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-2-21"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-3-16"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-4-12"><i class="fa fa-check"></i>Task 4</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#part-iii-the-bootstrap-1"><i class="fa fa-check"></i>Part III: The Bootstrap</a>
<ul>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-1-22"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-2-22"><i class="fa fa-check"></i>Task 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#bonus-1"><i class="fa fa-check"></i>Bonus</a>
<ul>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-1-23"><i class="fa fa-check"></i>Task 1</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-2-23"><i class="fa fa-check"></i>Task 2</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-3-17"><i class="fa fa-check"></i>Task 3</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-4-13"><i class="fa fa-check"></i>Task 4</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-5-9"><i class="fa fa-check"></i>Task 5</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-6-7"><i class="fa fa-check"></i>Task 6</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-7-5"><i class="fa fa-check"></i>Task 7</a></li>
<li class="chapter" data-level="" data-path="answers-3.html"><a href="answers-3.html#task-8-5"><i class="fa fa-check"></i>Task 8</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Section 5</b></span></li>
<li class="chapter" data-level="" data-path="overview-4.html"><a href="overview-4.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html"><i class="fa fa-check"></i>Practical 1: Academic Salary</a>
<ul>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#part-i"><i class="fa fa-check"></i>Part I</a>
<ul>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#exploring-the-data"><i class="fa fa-check"></i>Exploring the data</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#salary-and-years-since-phd"><i class="fa fa-check"></i>Salary and Years since PhD</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#salary-and-years-of-service"><i class="fa fa-check"></i>Salary and Years of Service</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#the-model"><i class="fa fa-check"></i>The Model</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#test-a-does-the-fitted-model-make-sense"><i class="fa fa-check"></i>Test a): Does the fitted model make sense?</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#test-b-overall-is-the-model-a-good-fit"><i class="fa fa-check"></i>Test b): Overall, is the model a good fit?</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#test-c-individually-are-the-explanatory-variables-important"><i class="fa fa-check"></i>Test c): Individually, are the explanatory variables important?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#part-ii"><i class="fa fa-check"></i>Part II</a>
<ul>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#interpreting-coefficients-of-attribute-variables"><i class="fa fa-check"></i>Interpreting coefficients of attribute variables</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#fitting-a-multivariate-regression-model"><i class="fa fa-check"></i>Fitting a Multivariate Regression Model</a></li>
<li class="chapter" data-level="" data-path="practical-1-academic-salary.html"><a href="practical-1-academic-salary.html#fitting-the-model"><i class="fa fa-check"></i>Fitting the Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-2-foreign-direct-investment-fdi-study.html"><a href="practical-2-foreign-direct-investment-fdi-study.html"><i class="fa fa-check"></i>Practical 2: Foreign Direct Investment (FDI) Study</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><i class="fa fa-check"></i>Demonstration 1: ProPublica‚Äôs Analysis of the COMPAS Tool</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#notes-on-the-data"><i class="fa fa-check"></i>Notes on the data</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#setup"><i class="fa fa-check"></i>Setup</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#load-packages"><i class="fa fa-check"></i>Load packages</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#load-data"><i class="fa fa-check"></i>Load data</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#inspect-data"><i class="fa fa-check"></i>Inspect data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#preprocess-data"><i class="fa fa-check"></i>Preprocess data</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#inspect-data-again"><i class="fa fa-check"></i>Inspect data again</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#exploratory-analysis"><i class="fa fa-check"></i>Exploratory analysis</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#exercise"><i class="fa fa-check"></i>üëâ Exercise</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#risk-labels"><i class="fa fa-check"></i>Risk labels</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#bias-in-compas"><i class="fa fa-check"></i>Bias in COMPAS</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#preprocess-data-for-logistic-regression"><i class="fa fa-check"></i>Preprocess data for logistic regression</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#estimate-the-logistic-regression-model"><i class="fa fa-check"></i>Estimate the logistic regression model</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#interpret-estimates"><i class="fa fa-check"></i>Interpret estimates</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#exercise-1"><i class="fa fa-check"></i>üëâ Exercise</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#predictive-accuracy"><i class="fa fa-check"></i>Predictive Accuracy</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#exercise-2"><i class="fa fa-check"></i>üëâ Exercise</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-propublicas-analysis-of-the-compas-tool.html"><a href="demonstration-1-propublicas-analysis-of-the-compas-tool.html#exercise-3"><i class="fa fa-check"></i>üëâ Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><i class="fa fa-check"></i>Demonstration 2: The Basics of Decision Trees and Related Methods</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html#decision-trees"><i class="fa fa-check"></i>Decision Trees</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html#classification-trees"><i class="fa fa-check"></i>Classification Trees</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html#regression-trees"><i class="fa fa-check"></i>Regression Trees</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html#ensemble-methods"><i class="fa fa-check"></i>Ensemble Methods</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html#bagging"><i class="fa fa-check"></i>Bagging</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html#random-forests"><i class="fa fa-check"></i>Random Forests</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-the-basics-of-decision-trees-and-related-methods.html"><a href="demonstration-2-the-basics-of-decision-trees-and-related-methods.html#boosting"><i class="fa fa-check"></i>Boosting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-4.html"><a href="answers-4.html"><i class="fa fa-check"></i>Answers</a>
<ul>
<li class="chapter" data-level="" data-path="answers-4.html"><a href="answers-4.html#practical-1-4"><i class="fa fa-check"></i>Practical 1</a>
<ul>
<li class="chapter" data-level="" data-path="answers-4.html"><a href="answers-4.html#part-i-1"><i class="fa fa-check"></i>Part I</a></li>
<li class="chapter" data-level="" data-path="answers-4.html"><a href="answers-4.html#part-ii-1"><i class="fa fa-check"></i>Part II</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="answers-4.html"><a href="answers-4.html#practical-2-4"><i class="fa fa-check"></i>Practical 2</a></li>
</ul></li>
<li class="part"><span><b>Section 6</b></span></li>
<li class="chapter" data-level="" data-path="overview-5.html"><a href="overview-5.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-subset-and-stepwise-selection.html"><a href="demonstration-1-subset-and-stepwise-selection.html"><i class="fa fa-check"></i>Demonstration 1: Subset and Stepwise Selection</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-subset-and-stepwise-selection.html"><a href="demonstration-1-subset-and-stepwise-selection.html#best-subset-selection"><i class="fa fa-check"></i>Best Subset Selection</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-subset-and-stepwise-selection.html"><a href="demonstration-1-subset-and-stepwise-selection.html#stepwise-selection"><i class="fa fa-check"></i>Stepwise Selection</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-subset-and-stepwise-selection.html"><a href="demonstration-1-subset-and-stepwise-selection.html#choosing-among-models-using-the-validation-set-approach-and-cross-validation"><i class="fa fa-check"></i>Choosing Among Models Using the Validation-Set Approach and Cross-Validation</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-subset-and-stepwise-selection.html"><a href="demonstration-1-subset-and-stepwise-selection.html#the-validation-set-approach-1"><i class="fa fa-check"></i>The Validation Set Approach</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-subset-and-stepwise-selection.html"><a href="demonstration-1-subset-and-stepwise-selection.html#cross-validation"><i class="fa fa-check"></i>Cross-validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2-regularisation.html"><a href="demonstration-2-regularisation.html"><i class="fa fa-check"></i>Demonstration 2: Regularisation</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-regularisation.html"><a href="demonstration-2-regularisation.html#ridge-regression"><i class="fa fa-check"></i>Ridge Regression</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-regularisation.html"><a href="demonstration-2-regularisation.html#the-lasso"><i class="fa fa-check"></i>The Lasso</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-3-pcr-and-pls-regression.html"><a href="demonstration-3-pcr-and-pls-regression.html"><i class="fa fa-check"></i>Demonstration 3: PCR and PLS Regression</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-3-pcr-and-pls-regression.html"><a href="demonstration-3-pcr-and-pls-regression.html#principal-components-regression"><i class="fa fa-check"></i>Principal Components Regression</a></li>
<li class="chapter" data-level="" data-path="demonstration-3-pcr-and-pls-regression.html"><a href="demonstration-3-pcr-and-pls-regression.html#partial-least-squares"><i class="fa fa-check"></i>Partial Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-4-beyond-linearity.html"><a href="demonstration-4-beyond-linearity.html"><i class="fa fa-check"></i>Demonstration 4: Beyond Linearity</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-4-beyond-linearity.html"><a href="demonstration-4-beyond-linearity.html#polynomial-regression-and-step-functions"><i class="fa fa-check"></i>Polynomial Regression and Step Functions</a></li>
<li class="chapter" data-level="" data-path="demonstration-4-beyond-linearity.html"><a href="demonstration-4-beyond-linearity.html#step-functions"><i class="fa fa-check"></i>Step Functions</a></li>
<li class="chapter" data-level="" data-path="demonstration-4-beyond-linearity.html"><a href="demonstration-4-beyond-linearity.html#splines"><i class="fa fa-check"></i>Splines</a></li>
<li class="chapter" data-level="" data-path="demonstration-4-beyond-linearity.html"><a href="demonstration-4-beyond-linearity.html#local-regression"><i class="fa fa-check"></i>Local Regression</a></li>
<li class="chapter" data-level="" data-path="demonstration-4-beyond-linearity.html"><a href="demonstration-4-beyond-linearity.html#generalised-additive-models"><i class="fa fa-check"></i>Generalised Additive Models</a></li>
</ul></li>
<li class="part"><span><b>Section 7</b></span></li>
<li class="chapter" data-level="" data-path="overview-6.html"><a href="overview-6.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html"><i class="fa fa-check"></i>Demonstration 1: K-means Clustering in R</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#loading-the-necessary-packages"><i class="fa fa-check"></i>Loading the necessary packages</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#profile-the-palmer-penguins-dataset"><i class="fa fa-check"></i>Profile the Palmer Penguins dataset</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#plot"><i class="fa fa-check"></i>Plot</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#preprocess-the-data-for-clustering"><i class="fa fa-check"></i>Preprocess the data for clustering</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#perform-k-means-clustering"><i class="fa fa-check"></i>Perform k-means clustering</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#visualise-the-clusters"><i class="fa fa-check"></i>Visualise the clusters</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#tasks"><i class="fa fa-check"></i>üëâ TASKS</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#task-1-how-well-did-k-means-clustering-perform"><i class="fa fa-check"></i>TASK 1: How well did k-means clustering perform?</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#task-2-how-many-clusters-should-we-use"><i class="fa fa-check"></i>TASK 2: How many clusters should we use?</a></li>
<li class="chapter" data-level="" data-path="demonstration-1-k-means-clustering-in-r.html"><a href="demonstration-1-k-means-clustering-in-r.html#task-3-clustering-cars"><i class="fa fa-check"></i>TASK 3: Clustering cars</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html"><i class="fa fa-check"></i>Demonstration 2: Principal Component Analysis in R</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#load-packages-1"><i class="fa fa-check"></i>Load packages</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#preprocess-the-world-happiness-report-data"><i class="fa fa-check"></i>Preprocess the world happiness report data</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#profile-the-happiness-data"><i class="fa fa-check"></i>Profile the happiness data</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#plot-happiness-score-against-feature"><i class="fa fa-check"></i>Plot happiness score against feature</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#run-pca-using-five-features"><i class="fa fa-check"></i>Run PCA using five features</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#correlations-of-happiness-score-with-pc1-and-pc2"><i class="fa fa-check"></i>Correlations of happiness score with PC1 and PC2</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#plot-first-two-principal-components"><i class="fa fa-check"></i>Plot first two principal components</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#regress-happiness-on-the-five-indicators"><i class="fa fa-check"></i>Regress happiness on the five indicators</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#visualise-happiness-against-principal-components"><i class="fa fa-check"></i>Visualise happiness against principal components</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#regress-happiness-on-first-principal-component"><i class="fa fa-check"></i>Regress happiness on first principal component</a></li>
<li class="chapter" data-level="" data-path="demonstration-2-principal-component-analysis-in-r.html"><a href="demonstration-2-principal-component-analysis-in-r.html#task"><i class="fa fa-check"></i>üëâ TASK</a></li>
</ul></li>
<li class="part"><span><b>Section 8</b></span></li>
<li class="chapter" data-level="" data-path="overview-7.html"><a href="overview-7.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html"><i class="fa fa-check"></i>Demonstration</a>
<ul>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#data-set"><i class="fa fa-check"></i>Data Set</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#project-planning-setting-the-stage-for-success"><i class="fa fa-check"></i>Project Planning: Setting the Stage for Success</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#data-preprocessing"><i class="fa fa-check"></i>Data Preprocessing</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#exploratory-data-analysis-eda"><i class="fa fa-check"></i>Exploratory Data Analysis (EDA)</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#model-selection-and-model-training"><i class="fa fa-check"></i>Model Selection and Model Training</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#model-evaluation"><i class="fa fa-check"></i>Model Evaluation</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#model-interpretation"><i class="fa fa-check"></i>Model Interpretation</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#report-conclusion"><i class="fa fa-check"></i>Report Conclusion</a></li>
<li class="chapter" data-level="" data-path="demonstration.html"><a href="demonstration.html#key-insights"><i class="fa fa-check"></i>Key Insights</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="your-turn.html"><a href="your-turn.html"><i class="fa fa-check"></i>üëâ Your Turn!</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SOST70033 Data Science Modelling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<hr>
<center> 
  <div class="header">
   <img src="images/banners/DSM_banner.png" alt="Trulli">
  </div>
</center>
<div id="demonstration-1-classification-problems" class="section level1 unnumbered hasAnchor">
<h1>Demonstration 1: Classification Problems<a href="demonstration-1-classification-problems.html#demonstration-1-classification-problems" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this demonstration, you will learn how to address classification problems using logistic regression, discriminant analysis, KNN, and Naive Bayes.</p>
<p>You will need the <strong>Weekly</strong> dataset, part of the <code>ISRL2</code> package. By loading the package, the <strong>Weekly</strong> dataset loads automatically.</p>
<p>In addition to the <code>ISLR2</code> package, will also require the following:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="demonstration-1-classification-problems.html#cb120-1" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb120-2"><a href="demonstration-1-classification-problems.html#cb120-2" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb120-3"><a href="demonstration-1-classification-problems.html#cb120-3" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb120-4"><a href="demonstration-1-classification-problems.html#cb120-4" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb120-5"><a href="demonstration-1-classification-problems.html#cb120-5" tabindex="-1"></a><span class="fu">library</span>(ISLR2)</span>
<span id="cb120-6"><a href="demonstration-1-classification-problems.html#cb120-6" tabindex="-1"></a><span class="fu">library</span>(e1071)</span></code></pre></div>
<div id="dataset-and-variables" class="section level2 unnumbered hasAnchor">
<h2>Dataset and Variables<a href="demonstration-1-classification-problems.html#dataset-and-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <strong>Weekly</strong> dataset contains weekly percentage returns for the S&amp;P 500 stock index between 1990 and 2010. It is a dataframe with 1098 observations and 9 variables. The variables are:</p>
<ul>
<li>Year: year observation was recorded<br />
</li>
<li>Lag1: Percentage return for previous week<br />
</li>
<li>Lag2: Percentage return for 2 weeks previous<br />
</li>
<li>Lag3: Percentage return for 3 weeks previous<br />
</li>
<li>Lag4: Percentage return for 4 weeks previous<br />
</li>
<li>Lag5: Percentage return for 5 weeks previous<br />
</li>
<li>Volume: Volume of shares traded (average number of daily shares traded in billions)<br />
</li>
<li>Today: percentage return for current week<br />
</li>
<li>Direction: whether the market had a positive (up) or negative (down) return on a given week.</li>
</ul>
<p>In this demonstration, the goal is to predict whether the market had a positive (up) or negative (down) return on a given week. Therefore, <strong>Direction</strong> will be our response variable.</p>
<p>Before we consider the model, let‚Äôs first explore our dataset.</p>
<p>By exploring the structure of the dataframe, we find out that all variables are numeric, with the exception of the <strong>Direction</strong> variable.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="demonstration-1-classification-problems.html#cb121-1" tabindex="-1"></a><span class="fu">str</span>(Weekly)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1089 obs. of  9 variables:
##  $ Year     : num  1990 1990 1990 1990 1990 1990 1990 1990 1990 1990 ...
##  $ Lag1     : num  0.816 -0.27 -2.576 3.514 0.712 ...
##  $ Lag2     : num  1.572 0.816 -0.27 -2.576 3.514 ...
##  $ Lag3     : num  -3.936 1.572 0.816 -0.27 -2.576 ...
##  $ Lag4     : num  -0.229 -3.936 1.572 0.816 -0.27 ...
##  $ Lag5     : num  -3.484 -0.229 -3.936 1.572 0.816 ...
##  $ Volume   : num  0.155 0.149 0.16 0.162 0.154 ...
##  $ Today    : num  -0.27 -2.576 3.514 0.712 1.178 ...
##  $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 1 1 2 2 2 1 2 2 2 1 ...</code></pre>
</div>
<div id="correlation-matrix-and-plot" class="section level2 unnumbered hasAnchor">
<h2>Correlation Matrix and Plot<a href="demonstration-1-classification-problems.html#correlation-matrix-and-plot" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let‚Äôs now produce a correlation plot between all pairs of <em>numeric</em> variables in the dataset.</p>
<p>Using the base R <code>cor()</code> function, we exclude the 9th variable (which is a factor) and compute the correlation among all pairs of numeric variables.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="demonstration-1-classification-problems.html#cb123-1" tabindex="-1"></a><span class="fu">cor</span>(Weekly[, <span class="sc">-</span><span class="dv">9</span>])</span></code></pre></div>
<pre><code>##               Year         Lag1        Lag2        Lag3         Lag4
## Year    1.00000000 -0.032289274 -0.03339001 -0.03000649 -0.031127923
## Lag1   -0.03228927  1.000000000 -0.07485305  0.05863568 -0.071273876
## Lag2   -0.03339001 -0.074853051  1.00000000 -0.07572091  0.058381535
## Lag3   -0.03000649  0.058635682 -0.07572091  1.00000000 -0.075395865
## Lag4   -0.03112792 -0.071273876  0.05838153 -0.07539587  1.000000000
## Lag5   -0.03051910 -0.008183096 -0.07249948  0.06065717 -0.075675027
## Volume  0.84194162 -0.064951313 -0.08551314 -0.06928771 -0.061074617
## Today  -0.03245989 -0.075031842  0.05916672 -0.07124364 -0.007825873
##                Lag5      Volume        Today
## Year   -0.030519101  0.84194162 -0.032459894
## Lag1   -0.008183096 -0.06495131 -0.075031842
## Lag2   -0.072499482 -0.08551314  0.059166717
## Lag3    0.060657175 -0.06928771 -0.071243639
## Lag4   -0.075675027 -0.06107462 -0.007825873
## Lag5    1.000000000 -0.05851741  0.011012698
## Volume -0.058517414  1.00000000 -0.033077783
## Today   0.011012698 -0.03307778  1.000000000</code></pre>
<p>We store the computed correlation matrix in a new object which we will then use to create a correlation matrix plot with the <code>corrplot()</code> function from the <code>corrplot</code> package.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="demonstration-1-classification-problems.html#cb125-1" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(Weekly[, <span class="sc">-</span><span class="dv">9</span>])</span>
<span id="cb125-2"><a href="demonstration-1-classification-problems.html#cb125-2" tabindex="-1"></a></span>
<span id="cb125-3"><a href="demonstration-1-classification-problems.html#cb125-3" tabindex="-1"></a><span class="fu">corrplot</span>(cor_matrix)</span></code></pre></div>
<p><img src="03-S03-D1_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>By using the default arguments, we obtain the correlation matrix in full, with each circle representing the correlation between each variable. The size of the circle represents the magnitude of the correlation, whilst the shade corresponds to both strength and direction of the correlation. As the legend illustrates, a perfect negative correlation (-1) is represented by dark red and a perfect positive correlation (+1) in dark blue. As you already know, the correlation matrix is symmetric around its diagonal. The diagonal area represents the correlation of each variable with itself, and therefore, this corresponds to a perfect correlation (dark blue).</p>
<p>To facilitate interpretation, particularly when we are dealing with a large number of variables, we can set the <code>diag</code> argument to <code>FALSE</code> to remove the correlation of each variable with itself from the plot. Because of its symmetric property, we can also display just half of the square since the parts on either side of the diagonal are mirror images. We can achieve this using the <code>type</code> argument. We can either choose to display the area above the diagonal or the area below the diagonal, as I did below. There are many other options if you want to further customise your correlation plot such using a different visualisation method of the direction and strength of the correlation using the <code>method</code> argument. Have a look at the documentaion of the <code>corrplot</code> function using ?.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="demonstration-1-classification-problems.html#cb126-1" tabindex="-1"></a><span class="fu">corrplot</span>(cor_matrix, <span class="at">type =</span> <span class="st">&quot;lower&quot;</span>, <span class="at">diag =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="03-S03-D1_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Now, the correlation plot only displays the correlations between the 8 numeric variables. We observe a strong positive correlation between volume of daily shares traded and the year the observation was recorded (dark blue). The correlations between other variables are quite weak but notably, we see that Lag1 and Lag3, Lag 2 and Lag4, Lag3 and Lag5, and Today and Lag2 are positively correlated with one another (albeit weakly). Other variables also appear weakly negatively correlated, such as Lag1 and Lag2.</p>
<p><em>Ok, so what was the purpose of computing the correlation matrix? You‚Äôll remember that multicollinearity is an issue in model building which can lead to inflated variances of the estimated coefficients. As a result of the shared variance between two highly correlated predictors, our ability to adequately evaluate the effect of the predictors on the outcome will be affected (e.g.¬†increased risk of overfitting). One way to deal with multicollinearity is to eliminate one of the highly correlated predictors.</em></p>
</div>
<div id="classic-logistic-regression" class="section level2 unnumbered hasAnchor">
<h2>‚ÄúClassic‚Äù Logistic Regression<a href="demonstration-1-classification-problems.html#classic-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now let‚Äôs build our logistic regression model the classic way.</p>
<p>Given the high correlation between <strong>Year</strong> and <strong>Volume</strong>, we have to reflect on how we want to address this. Assuming we have knowledge of important factors that can predict market movement (<strong>Direction</strong>), we decide to drop the <strong>Year</strong> variable rather than <strong>Volume</strong>* since the latter measures average number of daily shares traded (in billions).</p>
<p>You may remember that in R, these models are built using the base R <code>glm</code> function within which the <code>family</code> argument must be set to <code>binomial</code>.</p>
<p>Note that in this dataset, the <strong>Direction</strong> variable is already a factor so there is no need to perform any recoding/transformations but remember to ALWAYS explore your data in detail before you build any model.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="demonstration-1-classification-problems.html#cb127-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(Direction <span class="sc">~</span> Lag1 <span class="sc">+</span> Lag2 <span class="sc">+</span> Lag3 <span class="sc">+</span> Lag4 <span class="sc">+</span> Lag5 <span class="sc">+</span> Volume,</span>
<span id="cb127-2"><a href="demonstration-1-classification-problems.html#cb127-2" tabindex="-1"></a>           <span class="at">data =</span> Weekly, <span class="at">family =</span> binomial)</span>
<span id="cb127-3"><a href="demonstration-1-classification-problems.html#cb127-3" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + 
##     Volume, family = binomial, data = Weekly)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6949  -1.2565   0.9913   1.0849   1.4579  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  0.26686    0.08593   3.106   0.0019 **
## Lag1        -0.04127    0.02641  -1.563   0.1181   
## Lag2         0.05844    0.02686   2.175   0.0296 * 
## Lag3        -0.01606    0.02666  -0.602   0.5469   
## Lag4        -0.02779    0.02646  -1.050   0.2937   
## Lag5        -0.01447    0.02638  -0.549   0.5833   
## Volume      -0.02274    0.03690  -0.616   0.5377   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1496.2  on 1088  degrees of freedom
## Residual deviance: 1486.4  on 1082  degrees of freedom
## AIC: 1500.4
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The results show that only <strong>Lag2</strong> is significant at an alpha level of 0.05.</p>
<p>Ok, so let‚Äôs see now how well our model predicts whether the market had a positive or negative return in a given week.</p>
<div id="confusion-matrix" class="section level3 unnumbered hasAnchor">
<h3>Confusion Matrix<a href="demonstration-1-classification-problems.html#confusion-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, let‚Äôs assess the effectiveness of our model by comparing the actual values with those predicted by the model. We can do so using a <em>confusion matrix</em> which compares the model predictions with the true values.</p>
<p>Using <code>predict(fit, type = "response")</code>, we generate predictions from our model (<code>fit</code>) on the scale of the response variable (<code>type = "response"</code>). In this case, our response variable is measured on a probability scale.</p>
<p>We choose the standard threshold of 0.5 such that we label an observation as belonging to the <strong>Up</strong> category if its posterior probability is above 0.5 or as <strong>Down</strong> if the posterior probability is below 0.5. Hence, in this context, the <code>&gt; 0.5</code> argument transforms the predicted probabilities into a binary form such that predictions greater than 0.5 are labelled TRUE (so representing upward market movement), whilst the rest are labelled FALSE (representing downward market movement).</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="demonstration-1-classification-problems.html#cb129-1" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">&gt;</span> <span class="fl">0.5</span></span></code></pre></div>
<p>Now that we have the frequencies of the TRUE and FALSE instances, let‚Äôs build our two-way confusion matrix using the base R <code>table()</code> function. The <code>ifelse</code> function nested inside <code>table()</code> converts the logical TRUE and FALSE values in the <strong>pred</strong> object intro descriptive labels to facilitate interpretation; so, if <strong>pred</strong> is TRUE (&gt; 0.5), it becomes labelled as <code>Up (pred)</code>, whilst it is is FALSE, it is labelled as <code>"Down (pred)"</code>. To also include the actual values of market movement from the dataset, we also need to add <code>Weekly$Direction</code>as our argument.</p>
<p>Finally to ‚Äòforce‚Äô R to display the <code>conf_matrix</code> object we just created, we can place the entire code in single parentheses.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="demonstration-1-classification-problems.html#cb130-1" tabindex="-1"></a>(conf_matrix <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">ifelse</span>(pred, <span class="st">&quot;Up (pred)&quot;</span>, <span class="st">&quot;Down (pred)&quot;</span>), Weekly<span class="sc">$</span>Direction))</span></code></pre></div>
<pre><code>##              
##               Down  Up
##   Down (pred)   54  48
##   Up (pred)    430 557</code></pre>
<p>Now let‚Äôs interpret the results. The results in diagonal represent correct predictions of market movement whilst those in the off-diagonal represent misclassified observations. We can see that our model incorrectly classified 430 instances of market movement as upward movement when in fact they represented downward movement and 48 instances as downward movement when in fact they represented upward movement. Overall, our logistic regression model correctly predicts upwards movements well but it performs poorly at predicting downward movements.</p>
<p>We can also compute the overall fraction of correct predictions by dividing the number of correct predictions by total number of predictions. We therefore divide the sum of the diagonal values in our confusion matrix (numerator) by the sum of all elements of the matrix (denominator). We extract the diagonal values from the matrix using the base R <code>diag()</code> function.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="demonstration-1-classification-problems.html#cb132-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(conf_matrix)) <span class="sc">/</span> <span class="fu">sum</span>(conf_matrix)</span></code></pre></div>
<pre><code>## [1] 0.5610652</code></pre>
<p>The overall fraction of correct predictions is 0.561 (so our model makes correct predictions about 56.1% of the time).</p>
<p><strong>Right, so does that mean that this model will make correct predictions 56% of the time on a new, unseen dataset?</strong></p>
<p>You already know the answer :)! We used our entire dataset to fit our model. This means that we cannot say anything about how our model will perform on a different dataset and we no longer have any ‚Äòunseen‚Äô data left to test this out.</p>
</div>
</div>
<div id="logistic-regression-in-statistical-learning" class="section level2 unnumbered hasAnchor">
<h2>Logistic Regression in Statistical Learning<a href="demonstration-1-classification-problems.html#logistic-regression-in-statistical-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now, let‚Äôs consider logistic regression as applied in statistical learning.</p>
<p>We will again consider a basic fixed split. In this example, we will fit our model using data from 1990 up to 2008 and set the data from 2009 and 2010 aside; this will be our test dataset.</p>
<p>This is easily achieved by creating a vector of logical values from the data according to our <strong>Year</strong> criterion.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="demonstration-1-classification-problems.html#cb134-1" tabindex="-1"></a>train <span class="ot">&lt;-</span> Weekly<span class="sc">$</span>Year <span class="sc">&lt;</span> <span class="dv">2009</span></span></code></pre></div>
<p>In our previous model, we observed that <strong>Lag2</strong> was the only statistically significant predictor. To exemplify how we can use logistic regression in statistical learning, we will build a simple simple with only one predictor.</p>
<p>The approach to building the model is the same as the one with which you are already familiar. The exception, of course, is that we will only use part of the dataset to build our model (which in this case is referred to as <em>training the model</em>). To subset our dataset to only include data from years previous to 2009, we use the logical vector <strong>train</strong> we just created.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="demonstration-1-classification-problems.html#cb135-1" tabindex="-1"></a>fit_log_SL <span class="ot">&lt;-</span> <span class="fu">glm</span>(Direction <span class="sc">~</span> Lag2, <span class="at">data =</span> Weekly[train, ], <span class="at">family =</span> binomial)</span></code></pre></div>
<p>Now let‚Äôs generate predictions; the function and the overall structure of the code is the same as discussed earlier in the demonstration. The exception is that we used the trained model <code>fit_log_SL</code> to make predictions on the <em>test</em> dataset (<code>Weekly[!train, ]</code>). Using <code>!</code>, we tell R to not include the training data when generating predictions.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="demonstration-1-classification-problems.html#cb136-1" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_log_SL, Weekly[<span class="sc">!</span>train, ], <span class="at">type =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">&gt;</span> <span class="fl">0.5</span></span></code></pre></div>
<p>Now let‚Äôs compute the confusion matrix such that we can compare our predictions on the test data (<code>pred</code>) against the actual values in our dataset (<code>Weekly[!train, ]$Direction)</code>).</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="demonstration-1-classification-problems.html#cb137-1" tabindex="-1"></a>(t <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">ifelse</span>(pred, <span class="st">&quot;Up (pred)&quot;</span>, <span class="st">&quot;Down (pred)&quot;</span>), Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction))</span></code></pre></div>
<pre><code>##              
##               Down Up
##   Down (pred)    9  5
##   Up (pred)     34 56</code></pre>
<p>If we then compute the overall fraction of correct predictions for the test data we can see that this is higher than the value we obtained using the classical approach (<span class="math inline">\(0.561\)</span>).</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="demonstration-1-classification-problems.html#cb139-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(t)) <span class="sc">/</span> <span class="fu">sum</span>(t)</span></code></pre></div>
<pre><code>## [1] 0.625</code></pre>
</div>
<div id="linear-discriminant-analysis" class="section level2 unnumbered hasAnchor">
<h2>Linear Discriminant Analysis<a href="demonstration-1-classification-problems.html#linear-discriminant-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>How well would linear discriminant analysis address our binary classification problem?</p>
<p>In R, LDA can be performed using the <code>lda()</code> function from the <code>MASS</code> package. The basic structure of the function is similar to the other models you have built.</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="demonstration-1-classification-problems.html#cb141-1" tabindex="-1"></a>fit_lda <span class="ot">&lt;-</span> <span class="fu">lda</span>(Direction <span class="sc">~</span> Lag2, <span class="at">data =</span> Weekly[train, ])</span></code></pre></div>
<p>The output is, of course, different.</p>
<ul>
<li>prior probabilities of groups: these tells us the way in which the two classes are distributed in our <em>training data</em> (i.e.¬†44.8 % of the observations correspond to downward market movement whilst 55.2% to upward market movement).<br />
</li>
<li>group means: the average of our single predictor <strong>Lag2</strong> within each class, and are used by LDA as an estimate of <span class="math inline">\(Œº_{k}\)</span>.<br />
</li>
<li>coefficient(s) of linear discriminants: tells us how our predictor(s) influence the score that is used to classify the observations into one of the two categories. Here, the coefficient is positive 0.44 and so this indicates that higher values for <strong>Lag2</strong> will make the modelmore likely classify an observation as belonging to the <strong>Up</strong> class; also, the larger the absolute value of the coefficient, the stronger the influence on the model.</li>
</ul>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="demonstration-1-classification-problems.html#cb142-1" tabindex="-1"></a>fit_lda</span></code></pre></div>
<pre><code>## Call:
## lda(Direction ~ Lag2, data = Weekly[train, ])
## 
## Prior probabilities of groups:
##      Down        Up 
## 0.4477157 0.5522843 
## 
## Group means:
##             Lag2
## Down -0.03568254
## Up    0.26036581
## 
## Coefficients of linear discriminants:
##            LD1
## Lag2 0.4414162</code></pre>
<p>Now let‚Äôs consider what the <code>predict()</code> function does when applied in the context of LDA.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="demonstration-1-classification-problems.html#cb144-1" tabindex="-1"></a>result_lda <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_lda, Weekly[<span class="sc">!</span>train, ])</span></code></pre></div>
<p>The output will contain three components: <code>class</code>, <code>posterior</code>, and <code>x</code>, each of which can be accessed using <code>$</code>.</p>
<p>The <code>class</code> component is a factor that contains the predictions for market movement (up/down).</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="demonstration-1-classification-problems.html#cb145-1" tabindex="-1"></a>result_lda<span class="sc">$</span>class</span></code></pre></div>
<pre><code>##   [1] Up   Up   Down Down Up   Up   Up   Down Down Down Down Up   Up   Up   Up  
##  [16] Up   Up   Up   Up   Up   Down Up   Up   Up   Up   Up   Up   Up   Up   Up  
##  [31] Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Down
##  [46] Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Down Up   Up   Up  
##  [61] Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Down Up   Down Up  
##  [76] Up   Up   Up   Down Down Up   Up   Up   Up   Up   Down Up   Up   Up   Up  
##  [91] Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up   Up  
## Levels: Down Up</code></pre>
<p>The <code>posterior</code> component is matrix that contains the posterior probability that the corresponding observation belongs to a given class.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="demonstration-1-classification-problems.html#cb147-1" tabindex="-1"></a>result_lda<span class="sc">$</span>posterior</span></code></pre></div>
<pre><code>##           Down        Up
## 986  0.4736555 0.5263445
## 987  0.3558617 0.6441383
## 988  0.5132860 0.4867140
## 989  0.5142948 0.4857052
## 990  0.4799727 0.5200273
## 991  0.4597586 0.5402414
## 992  0.3771117 0.6228883
## 993  0.5184724 0.4815276
## 994  0.5480397 0.4519603
## 995  0.5146118 0.4853882
## 996  0.5504246 0.4495754
## 997  0.3055404 0.6944596
## 998  0.4268160 0.5731840
## 999  0.3637275 0.6362725
## 1000 0.4034316 0.5965684
## 1001 0.4256310 0.5743690
## 1002 0.4277053 0.5722947
## 1003 0.4548626 0.5451374
## 1004 0.4308002 0.5691998
## 1005 0.3674066 0.6325934
## 1006 0.5210641 0.4789359
## 1007 0.4426627 0.5573373
## 1008 0.3983332 0.6016668
## 1009 0.4170520 0.5829480
## 1010 0.4400457 0.5599543
## 1011 0.4872186 0.5127814
## 1012 0.4529323 0.5470677
## 1013 0.4844231 0.5155769
## 1014 0.4769786 0.5230214
## 1015 0.3531293 0.6468707
## 1016 0.3912903 0.6087097
## 1017 0.4373753 0.5626247
## 1018 0.4163510 0.5836490
## 1019 0.4583549 0.5416451
## 1020 0.4182305 0.5817695
## 1021 0.4454253 0.5545747
## 1022 0.4667580 0.5332420
## 1023 0.4126831 0.5873169
## 1024 0.4146279 0.5853721
## 1025 0.4814414 0.5185586
## 1026 0.4756405 0.5243595
## 1027 0.3860819 0.6139181
## 1028 0.4278606 0.5721394
## 1029 0.4599449 0.5400551
## 1030 0.5071309 0.4928691
## 1031 0.4042648 0.5957352
## 1032 0.4173045 0.5826955
## 1033 0.4520606 0.5479394
## 1034 0.4491759 0.5508241
## 1035 0.4304467 0.5695533
## 1036 0.4487621 0.5512379
## 1037 0.4544049 0.5455951
## 1038 0.4184691 0.5815309
## 1039 0.4637729 0.5362271
## 1040 0.4114393 0.5885607
## 1041 0.4605038 0.5394962
## 1042 0.5053429 0.4946571
## 1043 0.4728071 0.5271929
## 1044 0.4595437 0.5404563
## 1045 0.4368785 0.5631215
## 1046 0.4051682 0.5948318
## 1047 0.4553490 0.5446510
## 1048 0.4056270 0.5943730
## 1049 0.4352188 0.5647812
## 1050 0.4370488 0.5629512
## 1051 0.4410978 0.5589022
## 1052 0.4352756 0.5647244
## 1053 0.4296973 0.5703027
## 1054 0.4520034 0.5479966
## 1055 0.4194240 0.5805760
## 1056 0.4853885 0.5146115
## 1057 0.5411727 0.4588273
## 1058 0.4177113 0.5822887
## 1059 0.5100863 0.4899137
## 1060 0.4470646 0.5529354
## 1061 0.4816287 0.5183713
## 1062 0.4138300 0.5861700
## 1063 0.4157203 0.5842797
## 1064 0.5017234 0.4982766
## 1065 0.5216975 0.4783025
## 1066 0.3738247 0.6261753
## 1067 0.4666863 0.5333137
## 1068 0.3993705 0.6006295
## 1069 0.4506892 0.5493108
## 1070 0.4235170 0.5764830
## 1071 0.5036414 0.4963586
## 1072 0.4593288 0.5406712
## 1073 0.4587988 0.5412012
## 1074 0.3965787 0.6034213
## 1075 0.4428192 0.5571808
## 1076 0.4287787 0.5712213
## 1077 0.4202670 0.5797330
## 1078 0.4523464 0.5476536
## 1079 0.4258989 0.5741011
## 1080 0.4358286 0.5641714
## 1081 0.4409698 0.5590302
## 1082 0.4491046 0.5508954
## 1083 0.3986650 0.6013350
## 1084 0.4804910 0.5195090
## 1085 0.4487050 0.5512950
## 1086 0.4616361 0.5383639
## 1087 0.4074084 0.5925916
## 1088 0.4311115 0.5688885
## 1089 0.4452828 0.5547172</code></pre>
<p>The <code>x</code> component contains the linear discriminants.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="demonstration-1-classification-problems.html#cb149-1" tabindex="-1"></a>result_lda<span class="sc">$</span>x</span></code></pre></div>
<pre><code>##              LD1
## 986  -0.80594669
## 987   2.92755168
## 988  -2.01984129
## 989  -2.05074043
## 990  -0.99972841
## 991  -0.37865579
## 992   2.22702414
## 993  -2.17875113
## 994  -3.08806854
## 995  -2.06045158
## 996  -3.16178505
## 997   4.66982149
## 998   0.64322275
## 999   2.66623327
## 1000  1.38038783
## 1001  0.68030171
## 1002  0.61541353
## 1003 -0.22769145
## 1004  0.51874338
## 1005  2.54484381
## 1006 -2.25820605
## 1007  0.14971942
## 1008  1.54282900
## 1009  0.94956560
## 1010  0.23094000
## 1011 -1.22176077
## 1012 -0.16810026
## 1013 -1.13612602
## 1014 -0.90791384
## 1015  3.01892483
## 1016  1.76839269
## 1017  0.31392625
## 1018  0.97163642
## 1019 -0.33539700
## 1020  0.91248664
## 1021  0.06408467
## 1022 -0.59406691
## 1023  1.08728746
## 1024  1.02593061
## 1025 -1.04475287
## 1026 -0.86686213
## 1027  1.93613085
## 1028  0.61055795
## 1029 -0.38439421
## 1030 -1.83135657
## 1031  1.35390286
## 1032  0.94162011
## 1033 -0.14117387
## 1034 -0.05200779
## 1035  0.52977878
## 1036 -0.03920672
## 1037 -0.21356613
## 1038  0.90498257
## 1039 -0.50225234
## 1040  1.12657351
## 1041 -0.40160944
## 1042 -1.77662096
## 1043 -0.77990314
## 1044 -0.37203455
## 1045  0.32937582
## 1046  1.32521081
## 1047 -0.24269960
## 1048  1.31064407
## 1049  0.38102152
## 1050  0.32407882
## 1051  0.19827520
## 1052  0.37925585
## 1053  0.55317384
## 1054 -0.13940820
## 1055  0.87496626
## 1056 -1.16570091
## 1057 -2.87618875
## 1058  0.92881904
## 1059 -1.92184689
## 1060  0.01332181
## 1061 -1.05049128
## 1062  1.05109133
## 1063  0.99150015
## 1064 -1.66582548
## 1065 -2.27762836
## 1066  2.33428828
## 1067 -0.59185983
## 1068  1.50972278
## 1069 -0.09879791
## 1070  0.74651414
## 1071 -1.72453384
## 1072 -0.36541331
## 1073 -0.34908091
## 1074  1.59888886
## 1075  0.14486384
## 1076  0.58186590
## 1077  0.84848129
## 1078 -0.15000219
## 1079  0.67191480
## 1080  0.36204062
## 1081  0.20224795
## 1082 -0.04980071
## 1083  1.53223501
## 1084 -1.01561940
## 1085 -0.03744106
## 1086 -0.43648132
## 1087  1.25414279
## 1088  0.50903222
## 1089  0.06849883</code></pre>
<p>To obtain our predictions, we can simply extract the <code>class</code> element.</p>
<p>Alternatively, if we want to directly extract just the predictions from the <code>class</code> element, we can use the <code>predict</code> function as we did earlier in the demonstration.</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="demonstration-1-classification-problems.html#cb151-1" tabindex="-1"></a><span class="co">#either </span></span>
<span id="cb151-2"><a href="demonstration-1-classification-problems.html#cb151-2" tabindex="-1"></a>pred_lda <span class="ot">&lt;-</span> result_lda<span class="sc">$</span>class</span>
<span id="cb151-3"><a href="demonstration-1-classification-problems.html#cb151-3" tabindex="-1"></a></span>
<span id="cb151-4"><a href="demonstration-1-classification-problems.html#cb151-4" tabindex="-1"></a><span class="co">#or</span></span>
<span id="cb151-5"><a href="demonstration-1-classification-problems.html#cb151-5" tabindex="-1"></a>pred_lda <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_lda, Weekly[<span class="sc">!</span>train, ], <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>class</span></code></pre></div>
<p>Now let‚Äôs compute the confusion matrix for our LDA classifier such that we can compare our predictions on the test data against the actual values in our dataset.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="demonstration-1-classification-problems.html#cb152-1" tabindex="-1"></a>(t <span class="ot">&lt;-</span> <span class="fu">table</span>(pred_lda, Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction))</span></code></pre></div>
<pre><code>##         
## pred_lda Down Up
##     Down    9  5
##     Up     34 56</code></pre>
<p>And now the fraction of correct predictions which, we can see is identical to that obtained for logistic regression.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="demonstration-1-classification-problems.html#cb154-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(t)) <span class="sc">/</span> <span class="fu">sum</span>(t)</span></code></pre></div>
<pre><code>## [1] 0.625</code></pre>
</div>
<div id="quadratic-discriminant-analysis" class="section level2 unnumbered hasAnchor">
<h2>Quadratic Discriminant Analysis<a href="demonstration-1-classification-problems.html#quadratic-discriminant-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let‚Äôs now consider how quadratic discriminant analysis would address our binary classification problem. The code syntax is identical to that for linear discriminant analysis and the <code>qda</code> function is also part of the <code>MASS</code> package.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="demonstration-1-classification-problems.html#cb156-1" tabindex="-1"></a>fit_qda <span class="ot">&lt;-</span> <span class="fu">qda</span>(Direction <span class="sc">~</span> Lag2, <span class="at">data =</span> Weekly[train, ])</span></code></pre></div>
<p>In terms of prior probabilities and group means, the output is identical to that of linear discriminant analysis. However, the output does not include the coefficients of the <em>linear</em> discriminants for obvious reasons.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="demonstration-1-classification-problems.html#cb157-1" tabindex="-1"></a>fit_qda</span></code></pre></div>
<pre><code>## Call:
## qda(Direction ~ Lag2, data = Weekly[train, ])
## 
## Prior probabilities of groups:
##      Down        Up 
## 0.4477157 0.5522843 
## 
## Group means:
##             Lag2
## Down -0.03568254
## Up    0.26036581</code></pre>
<p>The prediction function works in the same way as for LDA, except that it will produce only two elements (<code>class</code>, and <code>posterior</code>); again, the <code>x</code> element will not be included since we are dealing with a quadratic function.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="demonstration-1-classification-problems.html#cb159-1" tabindex="-1"></a>pred_qda <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_qda, Weekly[<span class="sc">!</span>train, ], <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)<span class="sc">$</span>class</span></code></pre></div>
<p>The confusion matrix is computed in the same way.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="demonstration-1-classification-problems.html#cb160-1" tabindex="-1"></a>(t <span class="ot">&lt;-</span> <span class="fu">table</span>(pred_qda, Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction))</span></code></pre></div>
<pre><code>##         
## pred_qda Down Up
##     Down    0  0
##     Up     43 61</code></pre>
<p>The fraction of correct predictions is lower than that for logistic regression and for LDA. We therefore conclude that in this context, QDA does not perform well in comparison to the previous two approaches.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="demonstration-1-classification-problems.html#cb162-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(t)) <span class="sc">/</span> <span class="fu">sum</span>(t)</span></code></pre></div>
<pre><code>## [1] 0.5865385</code></pre>
</div>
<div id="k-nearest-neighbours" class="section level2 unnumbered hasAnchor">
<h2><span class="math inline">\(K\)</span>-nearest neighbours<a href="demonstration-1-classification-problems.html#k-nearest-neighbours" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Earlier in the course, we covered K-nearest neighbour classification. Let‚Äôs now explore how this approach is used in R and how it performs in the context of our market movement problem.</p>
<p>To implement KNN in R, the most commonly used package is <code>class</code>.</p>
<div class="attention">
<p>Note that it is possible to be confronted with the following error when loading the package:</p>
<p><code>Error: (converted from warning) package ‚Äòclass‚Äô was built under R version ...</code></p>
<p>This will occur if you are using an older version of R than that under which the package was built. The best option is to update RStudio. If that is not possible (e.g.¬†due to system requirements), then another option is to suppress it using <code>suppressWarnings(library(class))</code> in your console. This should allow you to use the functions from the package.</p>
</div>
<p>In R, we build our model using the <code>knn()</code> function from the <code>class</code> package. This function works differently to those we have covered so far for linear and logistic regression, and for LDA and QDA.</p>
<p>This is because the <code>knn()</code> function both fits the model AND generates predictions. There are four arguments required:</p>
<ul>
<li>argument 1: predictors in our <em>training</em> data,<br />
</li>
<li>argument 2: predictors in our <em>test</em> data,<br />
</li>
<li>argument 3: outcome variable in our <em>training</em> data,<br />
</li>
<li>argument 4: the value for <span class="math inline">\(k\)</span>; note the function specifies 1 nearest neighbour by default but I added it here for illustration purposes (this value needs to be added only when using a value other than 1).</li>
</ul>
<p>Now, you may wonder why I also included the <code>drop = FALSE</code> argument when I subsetting the dataset.</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="demonstration-1-classification-problems.html#cb164-1" tabindex="-1"></a>fit_knn <span class="ot">&lt;-</span> <span class="fu">knn</span>(Weekly[train, <span class="st">&quot;Lag2&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb164-2"><a href="demonstration-1-classification-problems.html#cb164-2" tabindex="-1"></a>               Weekly[<span class="sc">!</span>train, <span class="st">&quot;Lag2&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb164-3"><a href="demonstration-1-classification-problems.html#cb164-3" tabindex="-1"></a>               Weekly<span class="sc">$</span>Direction[train], </span>
<span id="cb164-4"><a href="demonstration-1-classification-problems.html#cb164-4" tabindex="-1"></a>               <span class="at">k =</span> <span class="dv">1</span></span>
<span id="cb164-5"><a href="demonstration-1-classification-problems.html#cb164-5" tabindex="-1"></a>               )</span></code></pre></div>
<p>Before we proceed to interpret the results, let‚Äôs see what output we would produce if we subsetted our dataset such that we extract our predictor from the training data without the <code>drop = FALSE</code> argument. This looks like a vector, right?</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="demonstration-1-classification-problems.html#cb165-1" tabindex="-1"></a>Weekly[train, <span class="st">&quot;Lag2&quot;</span>]</span></code></pre></div>
<pre><code>##   [1]   1.572   0.816  -0.270  -2.576   3.514   0.712   1.178  -1.372   0.807
##  [10]   0.041   1.253  -2.678  -1.793   2.820   4.022   0.750  -0.017   2.420
##  [19]  -1.225   1.171  -2.061   0.729   0.112   2.480  -1.552  -2.259  -2.428
##  [28]  -2.708  -2.292  -4.978   3.547   0.260  -2.032  -1.739  -1.693   1.781
##  [37]  -3.682   4.150  -2.487   2.343   0.606   1.077  -0.637   2.260   1.716
##  [46]  -0.284   1.508  -0.913  -2.349  -1.798   5.393   1.156   2.077   4.751
##  [55]   2.702  -0.924   1.318   1.209  -0.363  -1.635   2.106   0.037   1.343
##  [64]   0.999  -1.348   0.470  -1.329  -0.892   1.370   3.269  -2.668   0.754
##  [73]  -1.188  -1.745   0.787   1.649   1.044  -0.856   1.641  -0.015  -0.398
##  [82]   2.228   0.320  -1.601  -1.416   1.129  -0.521  -1.205   0.052   2.897
##  [91]  -2.115   1.853   0.401  -2.614  -1.694  -0.245   1.034   1.417   0.668
## [100]   5.018   3.169  -1.011   0.906  -0.807  -1.613   0.565   0.338  -0.255
## [109]   0.309  -2.001   0.346   1.345  -1.896  -0.483   0.682   2.906  -1.687
## [118]   0.858   0.853  -1.433   0.958   0.321  -0.450  -0.900  -1.486  -0.054
## [127]   2.062   0.692   0.241  -0.967   3.064  -1.256   0.246  -1.205  -0.002
## [136]   0.540   0.599   0.798  -2.029  -0.936  -1.903   2.253   0.576   1.106
## [145]  -0.263   1.161   0.999   0.823   0.442   0.387   1.741  -0.342  -0.923
## [154]  -1.529   1.888  -0.238   0.612   2.313  -0.969  -2.330   2.110   0.616
## [163]   0.834   0.078  -0.533  -1.427   0.102   1.607  -2.653   0.723   0.482
## [172]  -0.622   1.429   0.976  -0.029  -0.622  -0.800   0.884  -0.393   0.509
## [181]  -0.527   0.303   0.230   0.123   0.325   1.337   0.960   0.174   0.082
## [190]  -0.626  -0.262   0.798  -0.210   1.996  -1.327   0.984  -1.766   1.266
## [199]  -0.599   0.099   0.395  -0.207   0.528   0.214  -0.199   0.740   1.066
## [208]  -0.040   0.838  -1.857   0.079  -0.530  -0.346  -0.285   0.366   0.990
## [217]  -2.225  -3.216   0.298  -0.206   0.325   0.733  -0.685  -0.822   2.427
## [226]   0.530   0.612  -0.317  -0.048  -3.414   0.768   0.751   1.025  -0.231
## [235]   1.137  -0.255   1.061   0.377   2.183  -0.593  -0.597   0.643  -2.445
## [244]   0.661  -1.645   3.076  -0.897   1.910  -2.425   0.015  -0.190  -1.989
## [253]   0.223  -1.399   2.649   0.224  -0.122   0.307   1.148  -0.255   1.207
## [262]   1.756   0.587   0.106   1.274  -0.551   0.855   1.215   1.100  -0.052
## [271]   1.140   0.555  -0.145   1.223   1.051   1.044  -1.210   0.859   1.692
## [280]  -0.858   2.252   1.830  -0.902   2.133   0.633  -1.120   1.682  -0.709
## [289]  -0.685   0.739   0.159   0.668   1.568   1.863  -0.278   0.461  -0.329
## [298]   0.345   0.506  -1.321   1.875   0.364   1.240  -0.017   1.168   1.730
## [307]  -0.185  -0.712   0.650   0.127  -2.416   1.665   1.600   2.288   3.229
## [316]  -1.278   1.713  -2.232  -1.687   1.252   1.433  -0.787   1.605  -2.920
## [325]   1.313   1.301  -1.810   1.630   2.579   1.435  -1.384   0.626  -1.108
## [334]   0.149   0.568  -1.967  -1.711  -1.154  -0.443   4.181  -0.059   0.470
## [343]   0.274  -2.255   0.566   3.791   0.954  -0.122   2.225  -0.114   1.450
## [352]  -1.393   0.407   3.844   0.930   1.506   1.107  -2.301  -1.482   2.776
## [361]   1.058  -1.158   1.533   2.195  -0.728   2.030   0.432   2.396  -0.830
## [370]  -1.366   1.789  -1.466  -1.144  -1.303  -2.065  -2.672   3.889  -0.127
## [379]   6.219   1.453   0.603   2.083   0.148   1.147   4.110   0.608  -1.268
## [388]   3.338  -0.026  -0.151   2.566   0.889  -1.436  -3.506   2.523  -2.606
## [397]   3.289  -0.553   2.879  -0.557   2.096   0.202  -2.360  -0.267  -2.869
## [406]   1.409   0.091   3.742  -0.798   2.972  -3.090  -0.693  -1.090   4.120
## [415]  -4.856   3.646  -0.408   2.369   3.283   0.754   1.384   1.463   0.605
## [424]   1.224   2.859  -0.338   2.488  -1.072   1.085  -1.320   1.182  -1.147
## [433]   0.053   0.157  -1.770   2.112  -1.348   0.165   2.957   1.167   1.562
## [442]   1.926  -3.872  -1.765  -2.786  -2.451   1.740  -5.004  -5.184   3.611
## [451]   1.093   2.417  -4.034  -1.816   7.317   1.349   2.615   3.854  -1.340
## [460]   3.361   2.473  -1.308  -0.874   1.849   3.219   0.241   3.731  -2.496
## [469]  -1.453   4.444  -3.145  -0.748   0.739  -0.072   2.999   1.499   0.363
## [478]  -1.269   0.851   4.223  -2.177   2.870  -1.597   0.735  -0.535  -0.561
## [487]  -2.139   1.990  -2.569   3.803  -2.050   5.771   0.867   1.105  -4.359
## [496]  -2.080  -2.140   2.106   0.673   0.872   0.665  -0.411  -1.201  -4.348
## [505]   0.427   4.148  -6.632   4.348   4.708   0.536   1.885   1.858  -0.378
## [514]   1.177  -1.134   0.282   2.626   0.748  -1.891   1.643  -1.624  -5.634
## [523]   4.721  -2.615  -2.958  -0.946   5.686  -1.001   4.975   4.301  -1.891
## [532]   1.186 -10.538   5.748   1.247  -1.363  -0.815  -0.986  -2.056   7.202
## [541]  -1.375   0.515  -1.569   0.910   1.671   2.102  -1.973  -4.074   3.031
## [550]   0.609   1.351   0.987   0.951  -1.727  -1.920  -1.166  -0.843  -1.916
## [559]  -2.471   1.656  -1.242   3.415  -4.255   0.127  -1.897  -1.978   4.156
## [568]  -4.215  -0.473   1.097  -1.661   1.556   1.819   0.924  -0.404  -2.572
## [577]  -1.006  -4.277  -0.938  -0.062  -6.720  -0.930   1.799  -2.749   4.880
## [586]   5.026   0.810   1.082  -1.653   3.716  -1.089  -1.348   0.340  -4.000
## [595]   0.905  -0.079  -2.760   2.107  -0.397  -0.415   0.707  -1.992  -2.369
## [604]   1.976  -4.334  -4.217 -11.050   7.780   2.924   1.892  -1.664   2.900
## [613]  -1.576   3.045   1.637   1.027  -0.947   1.655  -3.041   1.941   1.409
## [622]   0.990  -2.295  -1.573   0.506  -0.978  -2.315   0.726  -1.299   3.848
## [631]   2.874   0.159  -1.497  -0.114  -2.149  -1.044   1.275  -4.342  -0.269
## [640]  -1.718   4.891  -2.058  -1.539  -3.712  -1.972  -1.800   0.069  -0.080
## [649]  -6.839  -7.992   0.600   1.337   5.137   2.215   1.302  -2.635  -2.418
## [658]  -0.460  -4.992  -2.132  -3.238   4.339   5.874   1.499   0.369  -0.690
## [667]   1.687   2.277   0.619  -2.572  -2.494   0.706  -2.273   3.791   2.089
## [676]  -2.780  -4.478  -0.662  -3.040   0.627   1.591  -0.828  -1.458   0.528
## [685]   7.503  -3.605   1.778  -1.200   2.911   0.585   3.479   0.358   1.167
## [694]  -1.173   3.254   2.508   0.086   0.716  -1.955   0.971   1.262  -0.483
## [703]   0.540  -1.855  -0.261   1.338   0.241   1.505   1.327  -0.270   1.735
## [712]  -3.807   3.310   0.797   0.121  -1.002   2.119   0.238  -0.272  -1.435
## [721]   2.214   0.312   1.191   1.352   0.664   1.149   1.207   1.602   0.151
## [730]  -0.913   1.028   0.267  -0.148   0.073   1.041  -3.137  -0.963  -0.155
## [739]   3.046  -0.218  -0.413   0.528  -2.920  -0.777  -0.273  -0.195   2.480
## [748]   0.162   1.245  -0.128  -0.052  -0.798  -1.117  -1.026  -1.379   1.429
## [757]  -3.426   0.078   3.151   0.858   0.529   0.924   0.412  -1.634   1.927
## [766]  -0.827  -1.242  -1.124   3.145   3.183   1.544  -1.168   1.052   0.720
## [775]  -0.266   0.522   1.334   0.148  -2.123  -0.141  -1.406   0.299   2.704
## [784]   0.189  -0.308   0.814   0.887  -1.803  -0.869  -1.532   0.128   0.706
## [793]  -3.266   0.831   0.411   1.253  -1.477   3.053   0.799  -0.230   0.175
## [802]   1.573  -2.086   0.241   1.458   1.325   0.469   0.041  -0.629   0.324
## [811]  -0.868  -1.198   1.072   1.926  -0.288  -1.827   1.112  -2.678  -0.780
## [820]  -0.588   1.595   1.813   1.195   1.097   1.601  -0.250  -0.451   0.631
## [829]   0.106  -1.606   2.977   0.168  -2.029   1.762  -1.534   0.234   1.598
## [838]   0.170  -0.171  -0.451   2.016  -0.329  -0.620   0.049  -0.492   1.719
## [847]  -0.051   1.156  -2.604  -1.875   1.036   0.630  -2.788  -0.061  -0.563
## [856]   2.065  -0.372  -2.314   0.331   3.085   0.063  -0.986   2.807  -0.554
## [865]   1.229  -0.922   1.597  -0.370   1.603   1.029   1.188   0.218   0.639
## [874]  -0.947   1.217   1.470  -0.018  -0.303   0.940   1.224  -1.144   0.534
## [883]  -0.606   1.491  -0.016  -0.582   1.843  -0.713   1.216  -0.299  -4.412
## [892]   1.130  -1.133   3.544  -1.062   1.612   0.630   2.168   0.655   0.773
## [901]   0.015   1.122  -0.461   1.360  -1.866   1.674  -1.980   0.053   1.802
## [910]   1.441  -1.185  -4.899  -1.775   1.436  -0.530   2.312  -0.364  -1.387
## [919]   2.112   2.796   0.066   2.020   0.270  -3.917   2.309  -1.669  -3.706
## [928]   0.347  -1.237   2.807   1.588  -2.440   1.125  -0.402  -4.522  -0.752
## [937]  -5.412   0.409   4.871  -4.596   1.405   0.231  -1.661  -2.800  -0.404
## [946]   3.212  -1.075   4.195  -2.742   4.314   0.540   1.149  -1.812   2.670
## [955]  -3.467   1.777  -2.835  -0.048  -3.096  -3.001  -1.211  -1.854   1.710
## [964]  -0.232   0.203   2.857   0.145  -0.462  -0.725  -3.159   0.756   0.270
## [973]  -3.331  -9.399 -18.195   4.596  -6.781  10.491  -3.898  -6.198  -8.389
## [982]  12.026  -2.251   0.418   0.926</code></pre>
<p>If you wrap the code within the <code>class</code> function you can indeed confirm that the output is a vector.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="demonstration-1-classification-problems.html#cb167-1" tabindex="-1"></a><span class="fu">class</span>(Weekly[train, <span class="st">&quot;Lag2&quot;</span>])</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<p>The <code>knn()</code> requires that the training and test data be specified as either a matrix or a dataframe.</p>
<p>If we set the <code>drop</code> argument to <code>FALSE</code>, then we are essentially telling R NOT to delete the dimensions of our object when we are subsetting it such that it keeps the row numbers, thereby producing a dataframe.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="demonstration-1-classification-problems.html#cb169-1" tabindex="-1"></a><span class="fu">class</span>(Weekly[train, <span class="st">&quot;Lag2&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>])</span></code></pre></div>
<pre><code>## [1] &quot;data.frame&quot;</code></pre>
<div class="attention">
<p>You must pay close attention to the requirements and specifications for the functions with which you build your models. Often, you will be prompted by error messages in the console.</p>
<p>For example, the <code>knn()</code> function expects either a matrix or a dataframe. If you do not set <code>drop = FALSE</code> you will not be able to proceed:</p>
<p><code>Error in knn(Weekly[train, "Lag2"], Weekly[!train, "Lag2"], Weekly$Direction[train], : dims of 'test' and 'train' differ</code></p>
<p>Other times, the error may be not so severe as to impede the function from working, but incorrectly structured data or improperly coded variables will lead to the function producing invalid results. Remember to carefully explore the arguments using the Help tab (e.g.¬†?knn).</p>
</div>
<p>Now let‚Äôs return to our results and produce a confusion matrix.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="demonstration-1-classification-problems.html#cb171-1" tabindex="-1"></a>(t <span class="ot">&lt;-</span> <span class="fu">table</span>(fit_knn, Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction))</span></code></pre></div>
<pre><code>##        
## fit_knn Down Up
##    Down   21 29
##    Up     22 32</code></pre>
<p>Our overall fraction of correct predictions is 0.5. Therefore, the KNN classifier (<span class="math inline">\(k = 1\)</span>) performs the worst out of all other classifiers we have explored so far (but only slightly worse than QDA).</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="demonstration-1-classification-problems.html#cb173-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(t)) <span class="sc">/</span> <span class="fu">sum</span>(t)</span></code></pre></div>
<pre><code>## [1] 0.5096154</code></pre>
<p>But before we move on to our next classifier, let‚Äôs consider other values for <span class="math inline">\(k\)</span> for illustration purposes. To ensure consistent results, we also set the seed (to 1 in this case).</p>
<p>We fit KNN for up to <span class="math inline">\(k = 30\)</span> by using the base R <code>sapply</code> to apply the <code>knn()</code> function to every integer from 1 to 30 and to then calculate the overall fraction of correct prediction.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="demonstration-1-classification-problems.html#cb175-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb175-2"><a href="demonstration-1-classification-problems.html#cb175-2" tabindex="-1"></a>knn_k <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>, <span class="cf">function</span>(k) {</span>
<span id="cb175-3"><a href="demonstration-1-classification-problems.html#cb175-3" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">knn</span>(Weekly[train, <span class="st">&quot;Lag2&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb175-4"><a href="demonstration-1-classification-problems.html#cb175-4" tabindex="-1"></a>             Weekly[<span class="sc">!</span>train, <span class="st">&quot;Lag2&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb175-5"><a href="demonstration-1-classification-problems.html#cb175-5" tabindex="-1"></a>             Weekly<span class="sc">$</span>Direction[train],</span>
<span id="cb175-6"><a href="demonstration-1-classification-problems.html#cb175-6" tabindex="-1"></a>             <span class="at">k =</span> k</span>
<span id="cb175-7"><a href="demonstration-1-classification-problems.html#cb175-7" tabindex="-1"></a>             )</span>
<span id="cb175-8"><a href="demonstration-1-classification-problems.html#cb175-8" tabindex="-1"></a>  <span class="fu">mean</span>(fit <span class="sc">==</span> Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction)</span>
<span id="cb175-9"><a href="demonstration-1-classification-problems.html#cb175-9" tabindex="-1"></a>  })</span></code></pre></div>
<p>We can then create a plot to observe at what value for <code>k</code> the overall fraction of correct predictions is highest. This fraction stabilises at a value for <span class="math inline">\(k\)</span> somewhere between <span class="math inline">\(k = 10\)</span> and <span class="math inline">\(k = 15\)</span>.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="demonstration-1-classification-problems.html#cb176-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>, knn_k, <span class="at">type =</span> <span class="st">&quot;o&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;k&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Fraction correct&quot;</span>)</span></code></pre></div>
<p><img src="03-S03-D1_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>We can find this out directly by asking R the index of the first time a maximum value among all other values appears. Our classifier appears to perform best when <span class="math inline">\(k = 12\)</span>.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="demonstration-1-classification-problems.html#cb177-1" tabindex="-1"></a>(k <span class="ot">&lt;-</span> <span class="fu">which.max</span>(knn_k))</span></code></pre></div>
<pre><code>## [1] 12</code></pre>
<p>Now let‚Äôs re-evaluate our KNN classifier on the test data using `<span class="math inline">\(k = 12\)</span> and compute the confusion matrix.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="demonstration-1-classification-problems.html#cb179-1" tabindex="-1"></a>fit_knn <span class="ot">&lt;-</span> <span class="fu">knn</span>(Weekly[train, <span class="st">&quot;Lag2&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb179-2"><a href="demonstration-1-classification-problems.html#cb179-2" tabindex="-1"></a>               Weekly[<span class="sc">!</span>train, <span class="st">&quot;Lag2&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb179-3"><a href="demonstration-1-classification-problems.html#cb179-3" tabindex="-1"></a>               Weekly<span class="sc">$</span>Direction[train], </span>
<span id="cb179-4"><a href="demonstration-1-classification-problems.html#cb179-4" tabindex="-1"></a>               <span class="at">k =</span> <span class="dv">12</span></span>
<span id="cb179-5"><a href="demonstration-1-classification-problems.html#cb179-5" tabindex="-1"></a>               )</span>
<span id="cb179-6"><a href="demonstration-1-classification-problems.html#cb179-6" tabindex="-1"></a></span>
<span id="cb179-7"><a href="demonstration-1-classification-problems.html#cb179-7" tabindex="-1"></a><span class="fu">table</span>(fit_knn , Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction)</span></code></pre></div>
<pre><code>##        
## fit_knn Down Up
##    Down   18 18
##    Up     25 43</code></pre>
<p>Now, the overall fraction of correct predictions is higher than it was for <span class="math inline">\(k = 1\)</span> but this fraction still does not outperform logistic regression and LDA.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="demonstration-1-classification-problems.html#cb181-1" tabindex="-1"></a><span class="fu">mean</span>(fit_knn <span class="sc">==</span> Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction)</span></code></pre></div>
<pre><code>## [1] 0.5865385</code></pre>
</div>
<div id="naive-bayes" class="section level2 unnumbered hasAnchor">
<h2>Naive Bayes<a href="demonstration-1-classification-problems.html#naive-bayes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Finally, let‚Äôs evaluate the performance of Naive Bayes and conclude which approach performs best for our market movement classification problem.</p>
<p>A useful package for Naive Bayes is <code>e1071</code>. Like the <code>class</code> package, do note that you may be prompted with a similar error when loading the package (this can also be addressed by either updating RStudio or suppressing the warning).</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="demonstration-1-classification-problems.html#cb183-1" tabindex="-1"></a>fit_NBayes <span class="ot">&lt;-</span> <span class="fu">naiveBayes</span>(Direction <span class="sc">~</span> Lag2, <span class="at">data =</span> Weekly, <span class="at">subset =</span> train)</span></code></pre></div>
<p>Before generating the predictions, let‚Äôs explore the output of the fit. There are two important components:
- A-priori probabilities: i.e.¬†prior probabilities (distribution of the classes for the response variable)<br />
- Conditional probabilities: parameters of the model for the predictor by class. For a numeric variable (as is our predictor in this case), the parameters shown are the mean <code>[,1]</code> and standard deviation <code>[,2]</code> for the predictor values in each class; for a categorical variable, these would be conditional probabilities for the predictor in each class.</p>
<p>The a priori probabilities can be extracted by specifying <code>fit_NBayes$apriori</code> and the conditional probabilities can be extracted using <code>fit_NBayes$tables</code>.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="demonstration-1-classification-problems.html#cb184-1" tabindex="-1"></a>fit_NBayes</span></code></pre></div>
<pre><code>## 
## Naive Bayes Classifier for Discrete Predictors
## 
## Call:
## naiveBayes.default(x = X, y = Y, laplace = laplace)
## 
## A-priori probabilities:
## Y
##      Down        Up 
## 0.4477157 0.5522843 
## 
## Conditional probabilities:
##       Lag2
## Y             [,1]     [,2]
##   Down -0.03568254 2.199504
##   Up    0.26036581 2.317485</code></pre>
<p>Now let‚Äôs predict market movement.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="demonstration-1-classification-problems.html#cb186-1" tabindex="-1"></a>pred_NBayes <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_NBayes, Weekly[<span class="sc">!</span>train, ], <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span></code></pre></div>
<p>And finally, generate our confusion matrix.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="demonstration-1-classification-problems.html#cb187-1" tabindex="-1"></a>(t <span class="ot">&lt;-</span> <span class="fu">table</span>(pred_NBayes, Weekly[<span class="sc">!</span>train, ]<span class="sc">$</span>Direction))</span></code></pre></div>
<pre><code>##            
## pred_NBayes Down Up
##        Down    0  0
##        Up     43 61</code></pre>
<p>Our overall fraction of correct predictions is <span class="math inline">\(0.5865385\)</span>. Naive Bayes performs slightly better than KNN with <span class="math inline">\(k = 1\)</span> (<span class="math inline">\(0.5\)</span>) and the same as QDA (<span class="math inline">\(0.5865385\)</span>).</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="demonstration-1-classification-problems.html#cb189-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(t)) <span class="sc">/</span> <span class="fu">sum</span>(t)</span></code></pre></div>
<pre><code>## [1] 0.5865385</code></pre>
<p><em>Based on the approaches we have implemented in this demonstration, logistic regression and LDA perform best.</em></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="overview-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="demonstration-2-poisson-versus-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
